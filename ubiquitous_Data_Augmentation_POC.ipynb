{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ubiquitous_Data_Augmentation_POC.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8lqXmpbqDTZ"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from os.path import join\n",
        "import string\n",
        "from cv2 import cv2\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from matplotlib import pyplot\n",
        "\n",
        "\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEgWWDzzqUzt"
      },
      "source": [
        "Import Tensorflow Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Wy2N2iDqI7f",
        "outputId": "3d085808-92c4-4168-f615-ee76c89fa2be"
      },
      "source": [
        "(train_dsf, val_dsf, test_dsf), metadata = tfds.load(\n",
        "    'tf_flowers',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")\n",
        "\n",
        "num_classes_dsf = metadata.features['label'].num_classes\n",
        "print(num_classes_dsf)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EhNyWOGqr7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d4e19e4-c937-474b-8e29-89cfcab265e5"
      },
      "source": [
        "(train_dscd, val_dscd, test_dscd), metadata = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        "    batch_size=64,\n",
        ")\n",
        "\n",
        "num_classes_dscd = metadata.features['label'].num_classes\n",
        "print(num_classes_dscd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmvTFKkfeZAB"
      },
      "source": [
        "Set up Obfuscation of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xURarDBTr6jr"
      },
      "source": [
        "\n",
        "IMG_SIZE = 180\n",
        "\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  layers.experimental.preprocessing.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "batch_size = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def prepare(ds, shuffle=False, augment=False):\n",
        "  # Resize and rescale all datasets\n",
        "  ds = ds.map(lambda x, y: (resize_and_rescale(x), y), \n",
        "              num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(1000)\n",
        "\n",
        "  # Batch all datasets\n",
        "  ds = ds.batch(batch_size)\n",
        "\n",
        "  # Use data augmentation only on the training set\n",
        "  if augment:\n",
        "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
        "                num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  # Use buffered prefecting on all datasets\n",
        "  return ds.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3VYIEB34n-z"
      },
      "source": [
        "train_ds = prepare(train_dsf, shuffle=True, augment=False)\n",
        "val_ds = prepare(val_dsf)\n",
        "test_ds = prepare(test_dsf, augment=False)\n",
        "test_ds_aug = prepare(test_dsf, augment=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2UwJT7c5Cp_"
      },
      "source": [
        "#Model with no augmentation tested on augmented data set\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes_dsf)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGTklLm45Owl",
        "outputId": "a2960a25-abd8-4923-9b33-684031aae522"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "92/92 [==============================] - 86s 909ms/step - loss: 1.2703 - accuracy: 0.4636 - val_loss: 1.1411 - val_accuracy: 0.5395\n",
            "Epoch 2/5\n",
            "92/92 [==============================] - 81s 879ms/step - loss: 0.9435 - accuracy: 0.6379 - val_loss: 0.9065 - val_accuracy: 0.6594\n",
            "Epoch 3/5\n",
            "92/92 [==============================] - 82s 885ms/step - loss: 0.7244 - accuracy: 0.7279 - val_loss: 0.8827 - val_accuracy: 0.7003\n",
            "Epoch 4/5\n",
            "92/92 [==============================] - 82s 891ms/step - loss: 0.5248 - accuracy: 0.8089 - val_loss: 1.0099 - val_accuracy: 0.6376\n",
            "Epoch 5/5\n",
            "92/92 [==============================] - 82s 889ms/step - loss: 0.3292 - accuracy: 0.8873 - val_loss: 0.9774 - val_accuracy: 0.7003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CPBi54p6cjJ",
        "outputId": "e5e34c79-a786-4d2a-e85c-19eb282cd7fe"
      },
      "source": [
        "loss, acc = model.evaluate(test_ds)\n",
        "loss, acc = model.evaluate(test_ds_aug)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 3s 268ms/step - loss: 0.9531 - accuracy: 0.6812\n",
            "12/12 [==============================] - 4s 300ms/step - loss: 1.2291 - accuracy: 0.5940\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg7lHGw2VdRN"
      },
      "source": [
        "Testing a Model with Obfuscated data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cha39fWaVZbp"
      },
      "source": [
        "train_ds = prepare(train_dsf, shuffle=True, augment=True)\n",
        "val_ds = prepare(val_dsf, augment=True)\n",
        "test_ds = prepare(test_dsf, augment=False)\n",
        "test_ds_aug = prepare(test_dsf, augment=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c68U9OEVmZE"
      },
      "source": [
        "#Model with augmentation tested on augmented data set\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes_dsf)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "id": "jwreGmBWVnYJ",
        "outputId": "d1d17d62-c40e-4e1e-fcf3-db3e5a380c82"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-0db7a47ef7ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:394 call\n        outputs = layer(inputs, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:219 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer max_pooling2d_9 is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: (None, None, 180, 180, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uGhsSvDVqnd",
        "outputId": "cb364e66-3ab8-4833-ab15-1dfbcf0e7c9f"
      },
      "source": [
        "loss, acc = model.evaluate(test_ds)\n",
        "loss, acc = model.evaluate(test_ds_aug)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 3s 240ms/step - loss: 0.7942 - accuracy: 0.6676\n",
            "12/12 [==============================] - 4s 301ms/step - loss: 0.7927 - accuracy: 0.6594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPbuTcSoeCFh"
      },
      "source": [
        "Testing other Randmization in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pipzE-mleBON"
      },
      "source": [
        "#Random Contrast\n",
        "\n",
        "IMG_SIZE = 180\n",
        "seed = 3\n",
        "\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  layers.experimental.preprocessing.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "#Augmentation Only RandomContrast\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomContrast((.8,1.5),seed=seed),\n",
        "])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a9wTocWq98T"
      },
      "source": [
        "train_ds = prepare(train_dsf, shuffle=True, augment=False)\n",
        "val_ds = prepare(val_dsf, augment=False)\n",
        "test_ds = prepare(test_dsf, augment=False)\n",
        "test_ds_aug = prepare(test_dsf, augment=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5RgNxTsrCTM",
        "outputId": "ca090923-bd9e-446b-c07b-cd2faa98e7d0"
      },
      "source": [
        "#Model with augmentation tested on augmented data set\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes_dsf)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "92/92 [==============================] - 94s 988ms/step - loss: 1.2935 - accuracy: 0.4574 - val_loss: 1.0667 - val_accuracy: 0.5995\n",
            "Epoch 2/5\n",
            "92/92 [==============================] - 89s 957ms/step - loss: 0.9572 - accuracy: 0.6206 - val_loss: 0.9226 - val_accuracy: 0.6403\n",
            "Epoch 3/5\n",
            "92/92 [==============================] - 89s 958ms/step - loss: 0.7665 - accuracy: 0.7047 - val_loss: 1.0260 - val_accuracy: 0.5995\n",
            "Epoch 4/5\n",
            "92/92 [==============================] - 89s 959ms/step - loss: 0.5818 - accuracy: 0.7854 - val_loss: 1.0129 - val_accuracy: 0.6294\n",
            "Epoch 5/5\n",
            "92/92 [==============================] - 89s 963ms/step - loss: 0.4020 - accuracy: 0.8597 - val_loss: 1.0754 - val_accuracy: 0.7003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bJtjOmUrIFC",
        "outputId": "fe0c21bd-1662-4f12-bd5c-cfdf806d9dc4"
      },
      "source": [
        "loss, acc = model.evaluate(test_ds)\n",
        "loss, acc = model.evaluate(test_ds_aug)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 4s 288ms/step - loss: 1.1241 - accuracy: 0.6621\n",
            "12/12 [==============================] - 3s 264ms/step - loss: 1.7732 - accuracy: 0.5477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHAy8YtdfWZQ"
      },
      "source": [
        "train_ds = prepare(train_dsf, shuffle=True, augment=True)\n",
        "val_ds = prepare(val_dsf, augment=True)\n",
        "test_ds = prepare(test_dsf, augment=False)\n",
        "test_ds_aug = prepare(test_dsf, augment=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIG3LVu9fiJG"
      },
      "source": [
        "#Model with augmentation tested on augmented data set\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes_dsf)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aan7AxKfjLo",
        "outputId": "5e49ea1c-cf56-4c36-ba2d-74a418816830"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "92/92 [==============================] - 90s 963ms/step - loss: 1.6020 - accuracy: 0.3123 - val_loss: 1.3813 - val_accuracy: 0.3597\n",
            "Epoch 2/5\n",
            "92/92 [==============================] - 89s 963ms/step - loss: 1.2194 - accuracy: 0.4843 - val_loss: 1.1706 - val_accuracy: 0.5395\n",
            "Epoch 3/5\n",
            "92/92 [==============================] - 89s 964ms/step - loss: 1.1282 - accuracy: 0.5453 - val_loss: 1.0997 - val_accuracy: 0.5722\n",
            "Epoch 4/5\n",
            "92/92 [==============================] - 89s 966ms/step - loss: 1.0228 - accuracy: 0.5923 - val_loss: 1.1572 - val_accuracy: 0.5477\n",
            "Epoch 5/5\n",
            "92/92 [==============================] - 89s 965ms/step - loss: 0.9464 - accuracy: 0.6257 - val_loss: 1.0311 - val_accuracy: 0.6104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73ASalqrflyb",
        "outputId": "81b028f7-e419-4770-dd21-77715069ecb4"
      },
      "source": [
        "loss, acc = model.evaluate(test_ds)\n",
        "loss, acc = model.evaluate(test_ds_aug)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 3s 264ms/step - loss: 0.8536 - accuracy: 0.6594\n",
            "12/12 [==============================] - 3s 267ms/step - loss: 0.9576 - accuracy: 0.6267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJYk68S9hYuz"
      },
      "source": [
        "\n",
        "#Augmentation Only RandomZoom\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomZoom((-0.3, -0.2),seed=seed,fill_mode='wrap'),\n",
        "])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdUdJTyxrUdV"
      },
      "source": [
        "train_ds = prepare(train_dsf, shuffle=True, augment=False)\n",
        "val_ds = prepare(val_dsf, augment=False)\n",
        "test_ds = prepare(test_dsf, augment=False)\n",
        "test_ds_aug = prepare(test_dsf, augment=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBaU2p6FrXPM",
        "outputId": "cd53c42f-a11d-4153-d49e-9f7e45478e91"
      },
      "source": [
        "#Model with augmentation tested on augmented data set\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes_dsf)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "92/92 [==============================] - 90s 965ms/step - loss: 1.2346 - accuracy: 0.4925 - val_loss: 1.0329 - val_accuracy: 0.6158\n",
            "Epoch 2/5\n",
            "92/92 [==============================] - 89s 960ms/step - loss: 0.9338 - accuracy: 0.6386 - val_loss: 1.0323 - val_accuracy: 0.6158\n",
            "Epoch 3/5\n",
            "92/92 [==============================] - 89s 963ms/step - loss: 0.7509 - accuracy: 0.7190 - val_loss: 0.9586 - val_accuracy: 0.6485\n",
            "Epoch 4/5\n",
            "92/92 [==============================] - 89s 964ms/step - loss: 0.5546 - accuracy: 0.7977 - val_loss: 0.9201 - val_accuracy: 0.6458\n",
            "Epoch 5/5\n",
            "92/92 [==============================] - 89s 966ms/step - loss: 0.3186 - accuracy: 0.8890 - val_loss: 1.0879 - val_accuracy: 0.6349\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_GKqejDrbYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f4990c2-989f-416a-d2c5-0021391e635d"
      },
      "source": [
        "loss, acc = model.evaluate(test_ds)\n",
        "loss, acc = model.evaluate(test_ds_aug)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 3s 265ms/step - loss: 0.9239 - accuracy: 0.6703\n",
            "12/12 [==============================] - 4s 316ms/step - loss: 1.0088 - accuracy: 0.6512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHeaH9elrWdl"
      },
      "source": [
        "train_ds = prepare(train_dsf, shuffle=True, augment=True)\n",
        "val_ds = prepare(val_dsf, augment=True)\n",
        "test_ds = prepare(test_dsf, augment=False)\n",
        "test_ds_aug = prepare(test_dsf, augment=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJyMekKIifc7",
        "outputId": "5958ad99-90d0-4492-8253-948e3b5e2ada"
      },
      "source": [
        "#Model with augmentation tested on augmented data set\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes_dsf)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "92/92 [==============================] - 96s 1s/step - loss: 1.2803 - accuracy: 0.4608 - val_loss: 1.1173 - val_accuracy: 0.5368\n",
            "Epoch 2/5\n",
            "92/92 [==============================] - 95s 1s/step - loss: 1.0035 - accuracy: 0.6005 - val_loss: 0.9997 - val_accuracy: 0.6458\n",
            "Epoch 3/5\n",
            "92/92 [==============================] - 95s 1s/step - loss: 0.8379 - accuracy: 0.6849 - val_loss: 0.8636 - val_accuracy: 0.6485\n",
            "Epoch 4/5\n",
            "92/92 [==============================] - 95s 1s/step - loss: 0.6735 - accuracy: 0.7446 - val_loss: 0.9905 - val_accuracy: 0.6322\n",
            "Epoch 5/5\n",
            "92/92 [==============================] - 96s 1s/step - loss: 0.5050 - accuracy: 0.8116 - val_loss: 0.9289 - val_accuracy: 0.6512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGCdwOMYiiJn",
        "outputId": "77f400af-cd80-4937-d4bd-a06e6b2278ae"
      },
      "source": [
        "#Results for RandomZoom\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "loss, acc = model.evaluate(test_ds_aug)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 3s 267ms/step - loss: 0.9376 - accuracy: 0.6621\n",
            "12/12 [==============================] - 4s 312ms/step - loss: 0.8505 - accuracy: 0.6703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2v2qoo1lKvr"
      },
      "source": [
        "Add in Augmentation such as Saturtaion, Brightness, Shifting, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMOq5KE6ALmr"
      },
      "source": [
        "def tfds_imgen(ds, imgen, batch_size, batches_per):\n",
        "    for images, labels in ds:\n",
        "        flow_ = imgen.flow(images, labels, batch_size=batch_size)\n",
        "        for _ in range(batches_per):\n",
        "            yield next(flow_)\n",
        "\n",
        "#Shifting Image\n",
        "imgen = ImageDataGenerator(width_shift_range=0.3)\n",
        "\n",
        "train_ds = prepare(train_dsf,shuffle=True)\n",
        "train_dsa = tfds_imgen(\n",
        "    prepare(train_dsf,shuffle=True).as_numpy_iterator(), imgen,\n",
        "    batch_size=32, batches_per=32 // 32)\n",
        "\n",
        "val_ds = prepare(train_dsf)\n",
        "val_dsa = tfds_imgen(prepare(val_dsf).as_numpy_iterator(), imgen, batch_size=32, batches_per=32 // 32)\n",
        "\n",
        "test_ds = prepare(test_dsf)\n",
        "test_ds_aug = tfds_imgen(prepare(test_dsf).as_numpy_iterator(), imgen, batch_size=32, batches_per=32 // 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joDiF7hLmcnV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96055406-4f5e-49c1-82e0-efae4a6767de"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes_dsf)\n",
        "])\n",
        "\n",
        "#Generation of ImageGenerator\n",
        "#model.fit_generator(alter_img, steps_per_epoch=5, ...)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "92/92 [==============================] - 134s 1s/step - loss: 1.2942 - accuracy: 0.4438 - val_loss: 0.9973 - val_accuracy: 0.6090\n",
            "Epoch 2/5\n",
            "92/92 [==============================] - 121s 1s/step - loss: 0.9961 - accuracy: 0.6127 - val_loss: 0.8701 - val_accuracy: 0.7003\n",
            "Epoch 3/5\n",
            "92/92 [==============================] - 121s 1s/step - loss: 0.7972 - accuracy: 0.7044 - val_loss: 0.6537 - val_accuracy: 0.7684\n",
            "Epoch 4/5\n",
            "92/92 [==============================] - 125s 1s/step - loss: 0.5958 - accuracy: 0.7844 - val_loss: 0.4455 - val_accuracy: 0.8576\n",
            "Epoch 5/5\n",
            "92/92 [==============================] - 133s 1s/step - loss: 0.3663 - accuracy: 0.8740 - val_loss: 0.3416 - val_accuracy: 0.8750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgF66Mu1yeAq",
        "outputId": "780f868f-c793-4a6a-baa3-ffe0295f1dff"
      },
      "source": [
        "print(\"W/O Shift\")\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "loss, acc = model.evaluate(test_ds_aug)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W/O Shift\n",
            "12/12 [==============================] - 4s 322ms/step - loss: 1.1487 - accuracy: 0.6376\n",
            "24/24 [==============================] - 12s 509ms/step - loss: 1.1503 - accuracy: 0.5967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3dsmUPQyejr",
        "outputId": "9230c38b-d628-4aee-b628-e4bade0feb23"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes_dsf)\n",
        "])\n",
        "\n",
        "#Generation of ImageGenerator\n",
        "#model.fit_generator(alter_img, steps_per_epoch=5, ...)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_dsa,\n",
        "  validation_data=val_dsa,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "92/92 [==============================] - 151s 2s/step - loss: 1.2669 - accuracy: 0.4639 - val_loss: 1.0519 - val_accuracy: 0.6076\n",
            "Epoch 2/5\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 460 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 460 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 12 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 12 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r92/92 [==============================] - 0s 879us/step - loss: 1.2669 - accuracy: 0.4639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4Md6c8sykS5",
        "outputId": "8f3648bd-a6d5-4990-a3ff-c63a7b2e6823"
      },
      "source": [
        "print(\"With Shift\")\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "loss, acc = model.evaluate(test_ds_aug)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Shift\n",
            "12/12 [==============================] - 4s 290ms/step - loss: 1.0075 - accuracy: 0.5886\n",
            "12/12 [==============================] - 6s 480ms/step - loss: 1.0318 - accuracy: 0.5640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg-88_oCA5qQ"
      },
      "source": [
        "\n",
        "#Brightness Image\n",
        "imgen = ImageDataGenerator(brightness_range=[0.8,1.2])\n",
        "\n",
        "train_ds = prepare(train_dsf,shuffle=True)\n",
        "train_dsa = tfds_imgen(\n",
        "    prepare(train_dsf,shuffle=True).as_numpy_iterator(), imgen,\n",
        "    batch_size=32, batches_per=32 // 32)\n",
        "\n",
        "val_ds = prepare(train_dsf)\n",
        "val_dsa = tfds_imgen(prepare(val_dsf).as_numpy_iterator(), imgen, batch_size=32, batches_per=32 // 32)\n",
        "\n",
        "test_ds = prepare(test_dsf)\n",
        "test_ds_aug = tfds_imgen(prepare(test_dsf).as_numpy_iterator(), imgen, batch_size=32, batches_per=32 // 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9PSx_8FB1kN",
        "outputId": "445fd1b5-91dd-41a6-d9cc-6e7b35728828"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes_dsf)\n",
        "])\n",
        "\n",
        "#Generation of ImageGenerator\n",
        "#model.fit_generator(alter_img, steps_per_epoch=5, ...)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs,\n",
        "  steps_per_epoch = len(train_ds) // 32,\n",
        "  validation_steps = len(val_ds) //32\n",
        "\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4.2569 - accuracy: 0.2031 - val_loss: 5.4401 - val_accuracy: 0.1875\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4.0718 - accuracy: 0.2500 - val_loss: 2.1841 - val_accuracy: 0.2188\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 3s 2s/step - loss: 2.0294 - accuracy: 0.1094 - val_loss: 1.7406 - val_accuracy: 0.2344\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 3s 2s/step - loss: 1.7719 - accuracy: 0.1719 - val_loss: 1.6034 - val_accuracy: 0.1719\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 3s 2s/step - loss: 1.5993 - accuracy: 0.2500 - val_loss: 1.5850 - val_accuracy: 0.2656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "puB5WltgB2HQ",
        "outputId": "ff4df2d6-225d-4e7f-f91a-78d183a09881"
      },
      "source": [
        "print(\"W/O Brightness\")\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "loss, acc = model.evaluate(test_ds_aug)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W/O Brightness\n",
            "12/12 [==============================] - 4s 299ms/step - loss: 1.5939 - accuracy: 0.2507\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-03cf4316d4e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W/O Brightness\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1464\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m             steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1362\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiLyNp7lB8R4",
        "outputId": "75845811-1014-448d-e798-ea0e3bc0d0a6"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes_dsf)\n",
        "])\n",
        "\n",
        "#Generation of ImageGenerator\n",
        "#model.fit_generator(alter_img, steps_per_epoch=5, ...)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_dsa,\n",
        "  validation_data=val_dsa,\n",
        "  epochs=epochs,\n",
        "  steps_per_epoch = len(train_dsa) // 32,\n",
        "  validation_steps = len(val_dsa) //32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "368/368 [==============================] - 462s 1s/step - loss: 7.4070 - accuracy: 0.5601 - val_loss: 1.2988 - val_accuracy: 0.4816\n",
            "Epoch 2/5\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1840 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1840 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 48 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 48 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r368/368 [==============================] - 0s 148us/step - loss: 7.4070 - accuracy: 0.5601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "9jGjDumuB8XH",
        "outputId": "d02685a5-6164-4890-c727-66366c532e11"
      },
      "source": [
        "print(\"With Brightness\")\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "loss, acc = model.evaluate(test_ds_aug)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Brightness\n",
            "12/12 [==============================] - 4s 289ms/step - loss: 1.5044 - accuracy: 0.3161\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-a5ff8dcfc929>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"With Brightness\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1464\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m             steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1362\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiTAKSoaDE6N"
      },
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "def myFunc(image):\n",
        "    image = np.array(image)\n",
        "    hsv_image = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
        "    return Image.fromarray(hsv_image)\n",
        "\n",
        "  #Brightness Image\n",
        "imgen = ImageDataGenerator(preprocessing_function=myFunc)\n",
        "\n",
        "train_ds = prepare(train_dsf,shuffle=True)\n",
        "train_dsa = tfds_imgen(\n",
        "    prepare(train_dsf,shuffle=True).as_numpy_iterator(), imgen,\n",
        "    batch_size=32, batches_per=32 // 32)\n",
        "\n",
        "val_ds = prepare(train_dsf)\n",
        "val_dsa = tfds_imgen(prepare(val_dsf).as_numpy_iterator(), imgen, batch_size=32, batches_per=32 // 32)\n",
        "\n",
        "test_ds = prepare(test_dsf)\n",
        "test_ds_aug = tfds_imgen(prepare(test_dsf).as_numpy_iterator(), imgen, batch_size=32, batches_per=32 // 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9QFHSR2FmuI",
        "outputId": "768a2de7-67fa-4c30-86be-ed43ecc06bed"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes_dsf)\n",
        "])\n",
        "\n",
        "#Generation of ImageGenerator\n",
        "#model.fit_generator(alter_img, steps_per_epoch=5, ...)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        "\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "92/92 [==============================] - 125s 1s/step - loss: 1.3704 - accuracy: 0.4237 - val_loss: 1.0610 - val_accuracy: 0.6087\n",
            "Epoch 2/5\n",
            "92/92 [==============================] - 124s 1s/step - loss: 0.9892 - accuracy: 0.6151 - val_loss: 0.8572 - val_accuracy: 0.6792\n",
            "Epoch 3/5\n",
            "92/92 [==============================] - 125s 1s/step - loss: 0.7822 - accuracy: 0.6975 - val_loss: 0.6173 - val_accuracy: 0.7946\n",
            "Epoch 4/5\n",
            "92/92 [==============================] - 124s 1s/step - loss: 0.5615 - accuracy: 0.8004 - val_loss: 0.3669 - val_accuracy: 0.9091\n",
            "Epoch 5/5\n",
            "92/92 [==============================] - 124s 1s/step - loss: 0.3718 - accuracy: 0.8733 - val_loss: 0.2929 - val_accuracy: 0.9111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP0IUhEqFqL4"
      },
      "source": [
        "print(\"W/O Color\")\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "loss, acc = model.evaluate(test_ds_aug)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHY-GQeGFqY7"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes_dsf)\n",
        "])\n",
        "\n",
        "#Generation of ImageGenerator\n",
        "#model.fit_generator(alter_img, steps_per_epoch=5, ...)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_dsa,\n",
        "  validation_data=val_dsa,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wujAP4fZFqgT"
      },
      "source": [
        "print(\"With Color\")\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "loss, acc = model.evaluate(test_ds_aug)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igtxMFg4g9Yn"
      },
      "source": [
        "Proof of Concept for Robustness\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBDqOAQKHIOu"
      },
      "source": [
        "#This function may very from the data import source another version is shown above for using the ImageGenerator frunction from Keras \n",
        "#however I did face issues with this so the standard tensorflow augmentations were used\n",
        "class standardize_and_robust():\n",
        "\n",
        "#Step 1: scaling images\n",
        "  def resize(image):\n",
        "    \n",
        "    IMG_SIZE = 180\n",
        "    img_adj = []\n",
        "    \n",
        "    resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  layers.experimental.preprocessing.Rescaling(1./255)\n",
        "])\n",
        "    img_adj = resize_and_rescale(image)\n",
        "\n",
        "    return img_adj\n",
        "\n",
        "#Step 2: Expand dataset \n",
        "  def data_augmentation(image,label,augment_list): \n",
        "    img = []\n",
        "    lab = []\n",
        "\n",
        "    for aug in augment_list:\n",
        "      for i in range(3):\n",
        "        seed = (i, 0)  # tuple of size (2,)\n",
        "\n",
        "        if aug == 'flip':\n",
        "          data_augmentation = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "                                  ])\n",
        "          img.append(data_augmentation)\n",
        "          continue\n",
        "        elif aug =='brightness':\n",
        "          stateless_random_brightness = tf.image.stateless_random_brightness(\n",
        "              image, max_delta=0.5, seed=seed)\n",
        "          img.append(stateless_random_brightness)\n",
        "          lab.append(label)\n",
        "          continue\n",
        "        elif aug == 'hue':\n",
        "          stateless_random_hue = tf.image.stateless_random_hue(image,.5,seed=seed)\n",
        "          img.append(stateless_random_hue)\n",
        "          lab.append(label)\n",
        "          continue\n",
        "        elif aug == 'contrast':\n",
        "          stateless_random_contrast = tf.image.stateless_random_contrast(image, .2,.5, seed=seed)\n",
        "          img.append(stateless_random_contrast)\n",
        "          lab.append(label)\n",
        "          continue\n",
        "        elif aug == 'crop':\n",
        "          stateless_random_crop = tf.image.stateless_random_crop(image,shape=(1,2,3),seed=seed)\n",
        "          img.append(stateless_random_crop)\n",
        "          lab.append(label)\n",
        "          continue\n",
        "        elif aug == 'quality':\n",
        "          stateless_random_jpeg_quality = tf.image.stateless_random_jpeg_quality(image,60, 95,seed=seed)\n",
        "          img.append(stateless_random_jpeg_quality) \n",
        "          lab.append(label) \n",
        "          continue\n",
        "        elif aug == 'staturation':\n",
        "          stateless_random_saturation = tf.image.stateless_random_saturation(image,.5,.95,seed=seed)\n",
        "          img.append(stateless_random_saturation) \n",
        "          lab.append(label)\n",
        "          continue\n",
        "\n",
        "\n",
        "    return img, lab"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94JCNDLsRSYq"
      },
      "source": [
        "train_ds = prepare(train_dsf, shuffle=True)\n",
        "val_ds = prepare(val_dsf,)\n",
        "test_ds = prepare(test_dsf)\n",
        "\n",
        "\n",
        "train_y = np.concatenate([y for x, y in train_ds], axis=0)\n",
        "train_X = np.concatenate([x for x, y in train_ds], axis=0)\n",
        "val_y  = np.concatenate([y for x, y in val_ds], axis=0)\n",
        "val_X = np.concatenate([x for x, y in val_ds], axis=0)\n",
        "test_y  = np.concatenate([y for x, y in test_ds], axis=0)\n",
        "test_X = np.concatenate([x for x, y in test_ds], axis=0)\n",
        "\n",
        "\n",
        "train_dsa = tf.data.Dataset.from_tensor_slices(standardize_and_robust.data_augmentation(train_X,train_y,['brightness']))\n",
        "val_dsa = tf.data.Dataset.from_tensor_slices(standardize_and_robust.data_augmentation(val_X,val_y,['brightness']))\n",
        "test_ds_aug = tf.data.Dataset.from_tensor_slices(standardize_and_robust.data_augmentation(test_X,test_y,['brightness']))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6si1XIQAa3mI",
        "outputId": "6c94002c-f1bb-4c5a-ab1c-c82bacfeeb26"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes_dsf)\n",
        "])\n",
        "\n",
        "#Generation of ImageGenerator\n",
        "#model.fit_generator(alter_img, steps_per_epoch=5, ...)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "92/92 [==============================] - 101s 1s/step - loss: 1.2667 - accuracy: 0.4625 - val_loss: 1.0583 - val_accuracy: 0.6322\n",
            "Epoch 2/5\n",
            "92/92 [==============================] - 100s 1s/step - loss: 0.9635 - accuracy: 0.6315 - val_loss: 0.9449 - val_accuracy: 0.6757\n",
            "Epoch 3/5\n",
            "92/92 [==============================] - 99s 1s/step - loss: 0.7406 - accuracy: 0.7245 - val_loss: 0.9078 - val_accuracy: 0.6921\n",
            "Epoch 4/5\n",
            "92/92 [==============================] - 104s 1s/step - loss: 0.5116 - accuracy: 0.8147 - val_loss: 1.0997 - val_accuracy: 0.5858\n",
            "Epoch 5/5\n",
            "92/92 [==============================] - 102s 1s/step - loss: 0.2956 - accuracy: 0.8978 - val_loss: 1.2043 - val_accuracy: 0.6512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR3UhzU0a9JE",
        "outputId": "d02b5e60-c175-4793-ea3b-666d469b85d2"
      },
      "source": [
        "print(\"With Color\")\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "loss, acc = model.evaluate(test_ds_aug)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Color\n",
            "12/12 [==============================] - 4s 311ms/step - loss: 1.1560 - accuracy: 0.6431\n",
            "3/3 [==============================] - 12s 4s/step - loss: 1.4178 - accuracy: 0.5795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGbYM2_Uf3dD",
        "outputId": "eb64a683-3c72-4f71-c2e6-03f8da273c7a"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes_dsf)\n",
        "])\n",
        "\n",
        "#Generation of ImageGenerator\n",
        "#model.fit_generator(alter_img, steps_per_epoch=5, ...)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_dsa,\n",
        "  validation_data=val_dsa,\n",
        "  epochs=epochs\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3mzRTW7f6WL"
      },
      "source": [
        "print(\"With quality\")\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "loss, acc = model.evaluate(test_ds_aug)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTrZu7eThg6X"
      },
      "source": [
        "train_ds = prepare(train_dsf, shuffle=True)\n",
        "val_ds = prepare(val_dsf,)\n",
        "test_ds = prepare(test_dsf)\n",
        "\n",
        "\n",
        "train_y = np.concatenate([y for x, y in train_ds], axis=0)\n",
        "train_X = np.concatenate([x for x, y in train_ds], axis=0)\n",
        "val_y  = np.concatenate([y for x, y in val_ds], axis=0)\n",
        "val_X = np.concatenate([x for x, y in val_ds], axis=0)\n",
        "test_y  = np.concatenate([y for x, y in test_ds], axis=0)\n",
        "test_X = np.concatenate([x for x, y in test_ds], axis=0)\n",
        "\n",
        "\n",
        "train_dsa = tf.data.Dataset.from_tensor_slices(standardize_and_robust.data_augmentation(train_X,train_y,['hue']))\n",
        "val_dsa = tf.data.Dataset.from_tensor_slices(standardize_and_robust.data_augmentation(val_X,val_y,['hue']))\n",
        "test_ds_aug = tf.data.Dataset.from_tensor_slices(standardize_and_robust.data_augmentation(test_X,test_y,['hue']))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fQX1d5uhqkB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d47dd3d-dd65-46b7-95a4-c2d088eb2880"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes_dsf)\n",
        "])\n",
        "\n",
        "#Generation of ImageGenerator\n",
        "#model.fit_generator(alter_img, steps_per_epoch=5, ...)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "92/92 [==============================] - 101s 1s/step - loss: 1.3913 - accuracy: 0.4166 - val_loss: 1.1340 - val_accuracy: 0.5695\n",
            "Epoch 2/5\n",
            "92/92 [==============================] - 99s 1s/step - loss: 1.0361 - accuracy: 0.5869 - val_loss: 1.0707 - val_accuracy: 0.5777\n",
            "Epoch 3/5\n",
            "92/92 [==============================] - 99s 1s/step - loss: 0.8576 - accuracy: 0.6747 - val_loss: 0.9402 - val_accuracy: 0.6294\n",
            "Epoch 4/5\n",
            "92/92 [==============================] - 98s 1s/step - loss: 0.6705 - accuracy: 0.7425 - val_loss: 0.9329 - val_accuracy: 0.6512\n",
            "Epoch 5/5\n",
            "92/92 [==============================] - 98s 1s/step - loss: 0.4400 - accuracy: 0.8420 - val_loss: 1.1066 - val_accuracy: 0.6294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHqso1EihuLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4a34c9b-4f43-40b5-e952-d57cb1236673"
      },
      "source": [
        "print(\"With/o hue\")\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "loss, acc = model.evaluate(test_ds_aug)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With/o hue\n",
            "12/12 [==============================] - 4s 295ms/step - loss: 0.9800 - accuracy: 0.6839\n",
            "3/3 [==============================] - 10s 3s/step - loss: 3.4318 - accuracy: 0.3415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIooH7Bbh17E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39913391-09cc-4a48-a365-3928cffe4ed4"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes_dsf)\n",
        "])\n",
        "\n",
        "#Generation of ImageGenerator\n",
        "#model.fit_generator(alter_img, steps_per_epoch=5, ...)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_dsa,\n",
        "  validation_data=val_dsa,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seiXfQrvh20L"
      },
      "source": [
        "print(\"With hue\")\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "loss, acc = model.evaluate(test_ds_aug)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDNwrqlVuhez"
      },
      "source": [
        "train_ds = prepare(train_dsf, shuffle=True)\n",
        "val_ds = prepare(val_dsf,)\n",
        "test_ds = prepare(test_dsf)\n",
        "\n",
        "\n",
        "train_y = np.concatenate([y for x, y in train_ds], axis=0)\n",
        "train_X = np.concatenate([x for x, y in train_ds], axis=0)\n",
        "val_y  = np.concatenate([y for x, y in val_ds], axis=0)\n",
        "val_X = np.concatenate([x for x, y in val_ds], axis=0)\n",
        "test_y  = np.concatenate([y for x, y in test_ds], axis=0)\n",
        "test_X = np.concatenate([x for x, y in test_ds], axis=0)\n",
        "\n",
        "\n",
        "train_dsa = tf.data.Dataset.from_tensor_slices(standardize_and_robust.data_augmentation(train_X,train_y,['staturation']))\n",
        "val_dsa = tf.data.Dataset.from_tensor_slices(standardize_and_robust.data_augmentation(val_X,val_y,['staturation']))\n",
        "test_ds_aug = tf.data.Dataset.from_tensor_slices(standardize_and_robust.data_augmentation(test_X,test_y,['staturation']))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpe-8AGRvMG8",
        "outputId": "2f474a4e-9617-4db9-93d5-bc61ccaa0ff8"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes_dsf)\n",
        "])\n",
        "\n",
        "#Generation of ImageGenerator\n",
        "#model.fit_generator(alter_img, steps_per_epoch=5, ...)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "92/92 [==============================] - 109s 1s/step - loss: 1.2504 - accuracy: 0.4745 - val_loss: 1.0864 - val_accuracy: 0.5668\n",
            "Epoch 2/5\n",
            "92/92 [==============================] - 107s 1s/step - loss: 0.9578 - accuracy: 0.6202 - val_loss: 0.9162 - val_accuracy: 0.6757\n",
            "Epoch 3/5\n",
            "92/92 [==============================] - 107s 1s/step - loss: 0.8115 - accuracy: 0.6870 - val_loss: 0.8949 - val_accuracy: 0.6676\n",
            "Epoch 4/5\n",
            "92/92 [==============================] - 104s 1s/step - loss: 0.6560 - accuracy: 0.7602 - val_loss: 0.9764 - val_accuracy: 0.6213\n",
            "Epoch 5/5\n",
            "92/92 [==============================] - 102s 1s/step - loss: 0.4426 - accuracy: 0.8426 - val_loss: 0.9803 - val_accuracy: 0.6649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ_USp_FvPFU",
        "outputId": "a4cdcdf7-3d37-41ec-b862-f732eb4b3e98"
      },
      "source": [
        "print(\"With/o Staturation\")\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "loss, acc = model.evaluate(test_ds_aug)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With/o Staturation\n",
            "12/12 [==============================] - 4s 296ms/step - loss: 0.9559 - accuracy: 0.6921\n",
            "3/3 [==============================] - 10s 3s/step - loss: 1.2222 - accuracy: 0.5804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9HRJdmHvR78"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes_dsf)\n",
        "])\n",
        "\n",
        "#Generation of ImageGenerator\n",
        "#model.fit_generator(alter_img, steps_per_epoch=5, ...)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_dsa,\n",
        "  validation_data=val_dsa,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzHq6xWsvWzm"
      },
      "source": [
        "print(\"With Staturation\")\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "loss, acc = model.evaluate(test_ds_aug)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}